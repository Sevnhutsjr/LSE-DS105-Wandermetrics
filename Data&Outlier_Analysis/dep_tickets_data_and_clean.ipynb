{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Departure tickets data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "import keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(data, prefix=\"\"):\n",
    "    flattened = {}\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            if isinstance(value, (dict, list)):\n",
    "                flattened.update(flatten(value, f\"{prefix}{key}.\"))\n",
    "            else:\n",
    "                flattened[f\"{prefix}{key}\"] = value\n",
    "    elif isinstance(data, list):\n",
    "        for i, value in enumerate(data):\n",
    "            if isinstance(value, (dict, list)):\n",
    "                flattened.update(flatten(value, f\"{prefix}{i}_\"))\n",
    "            else:\n",
    "                flattened[f\"{prefix}{i}\"] = value\n",
    "\n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "def fridays_between_months(year, start_month, end_month):\n",
    "    fridays = []\n",
    "    \n",
    "    d = date(year, start_month, 1)\n",
    "    \n",
    "    while d.month <= end_month:\n",
    "        if d.weekday() == 4:  \n",
    "            fridays.append(d)\n",
    "        d += timedelta(days=1)\n",
    "    \n",
    "    return fridays\n",
    "\n",
    "fridays = fridays_between_months(2023, 6, 9)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://skyscanner44.p.rapidapi.com/search-extended\"\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": keys.api_key,\n",
    "    \"X-RapidAPI-Host\": \"skyscanner44.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "paris_responses = []\n",
    "\n",
    "for friday in fridays:\n",
    "    querystring = {\n",
    "        \"adults\": \"1\",\n",
    "        \"origin\": \"LOND\",\n",
    "        \"destination\": \"PARI\",\n",
    "        \"departureDate\": friday.isoformat(),\n",
    "        \"cabinClass\": \"economy\",\n",
    "        \"currency\": \"GBP\",\n",
    "        \"stops\": \"0\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    paris_responses.append(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "paris_dataframes = []\n",
    "\n",
    "for response_text in paris_responses:\n",
    "    paris = json.loads(response_text)[\"itineraries\"]\n",
    "    paris = paris[\"results\"]\n",
    "    flattened_data = [flatten(d) for d in paris]\n",
    "    paris = pd.DataFrame(flattened_data)\n",
    "    paris_dataframes.append(paris)\n",
    "\n",
    "par_dep_0501 = pd.concat(paris_dataframes, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Berlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://skyscanner44.p.rapidapi.com/search-extended\"\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": keys.api_key,\n",
    "    \"X-RapidAPI-Host\": \"skyscanner44.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "berlin_responses = []\n",
    "\n",
    "for friday in fridays:\n",
    "    querystring = {\n",
    "        \"adults\": \"1\",\n",
    "        \"origin\": \"LOND\",\n",
    "        \"destination\": \"BER\",\n",
    "        \"departureDate\": friday.strftime(\"%Y-%m-%d\"),\n",
    "        \"cabinClass\": \"economy\",\n",
    "        \"currency\": \"GBP\",\n",
    "        \"stops\": \"0\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    berlin_responses.append(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "berlin_dataframes = []\n",
    "\n",
    "for response_text in berlin_responses:\n",
    "    berlin = json.loads(response_text)[\"itineraries\"]\n",
    "    berlin = berlin[\"results\"]\n",
    "    flattened_data = [flatten(d) for d in berlin]\n",
    "    berlin = pd.DataFrame(flattened_data)\n",
    "    berlin_dataframes.append(berlin)\n",
    "\n",
    "ber_dep_0501 = pd.concat(berlin_dataframes, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Madrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://skyscanner44.p.rapidapi.com/search-extended\"\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": keys.api_key,\n",
    "    \"X-RapidAPI-Host\": \"skyscanner44.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "madrid_responses = []\n",
    "\n",
    "for friday in fridays:\n",
    "    querystring = {\n",
    "        \"adults\": \"1\",\n",
    "        \"origin\": \"LOND\",\n",
    "        \"destination\": \"MAD\",\n",
    "        \"departureDate\": friday.strftime(\"%Y-%m-%d\"),\n",
    "        \"cabinClass\": \"economy\",\n",
    "        \"currency\": \"GBP\",\n",
    "        \"stops\": \"0\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    madrid_responses.append(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "madrid_dataframes = []\n",
    "\n",
    "for response_text in madrid_responses:\n",
    "    madrid = json.loads(response.text)[\"itineraries\"]\n",
    "    madrid = madrid[\"results\"]\n",
    "    flattened_data = [flatten(d) for d in madrid]\n",
    "    madrid = pd.DataFrame(flattened_data)\n",
    "    madrid_dataframes.append(madrid)\n",
    "\n",
    "mar_dep_0501 = pd.concat(madrid_dataframes, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Lisbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://skyscanner44.p.rapidapi.com/search-extended\"\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": keys.api_key,\n",
    "    \"X-RapidAPI-Host\": \"skyscanner44.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "lisbon_responses = []\n",
    "\n",
    "for friday in fridays:\n",
    "    querystring = {\n",
    "        \"adults\": \"1\",\n",
    "        \"origin\": \"LOND\",\n",
    "        \"destination\": \"LIS\",\n",
    "        \"departureDate\": friday.strftime(\"%Y-%m-%d\"),\n",
    "        \"cabinClass\": \"economy\",\n",
    "        \"currency\": \"GBP\",\n",
    "        \"stops\": \"0\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    lisbon_responses.append(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "lisbon_dataframes = []\n",
    "\n",
    "for response_text in lisbon_responses:\n",
    "    lisbon = json.loads(response.text)[\"itineraries\"]\n",
    "    lisbon = lisbon[\"results\"]\n",
    "    flattened_data = [flatten(d) for d in lisbon]\n",
    "    lisbon = pd.DataFrame(flattened_data)\n",
    "    lisbon_dataframes.append(lisbon)\n",
    "\n",
    "lis_dep_0501 = pd.concat(lisbon_dataframes, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Rome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://skyscanner44.p.rapidapi.com/search-extended\"\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": keys.api_key,\n",
    "    \"X-RapidAPI-Host\": \"skyscanner44.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "rome_responses = []\n",
    "\n",
    "\n",
    "for friday in fridays:\n",
    "    querystring = {\n",
    "        \"adults\": \"1\",\n",
    "        \"origin\": \"LOND\",\n",
    "        \"destination\": \"ROME\",\n",
    "        \"departureDate\": friday.strftime(\"%Y-%m-%d\"),\n",
    "        \"cabinClass\": \"economy\",\n",
    "        \"currency\": \"GBP\",\n",
    "        \"stops\": \"0\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    rome_responses.append(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "rome_dataframes = []\n",
    "\n",
    "for response_text in rome_responses:\n",
    "    rome = json.loads(response_text)[\"itineraries\"]\n",
    "    rome = rome[\"results\"]\n",
    "    flattened_data = [flatten(d) for d in rome]\n",
    "    rome = pd.DataFrame(flattened_data)\n",
    "    rome_dataframes.append(rome)\n",
    "\n",
    "rome_dep_0501 = pd.concat(rome_dataframes, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Budapest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://skyscanner44.p.rapidapi.com/search-extended\"\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": keys.api_key,\n",
    "    \"X-RapidAPI-Host\": \"skyscanner44.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "budapest_responses = []\n",
    "\n",
    "for friday in fridays:\n",
    "    querystring = {\n",
    "        \"adults\": \"1\",\n",
    "        \"origin\": \"LOND\",\n",
    "        \"destination\": \"BUD\",\n",
    "        \"departureDate\": friday.strftime(\"%Y-%m-%d\"),\n",
    "        \"cabinClass\": \"economy\",\n",
    "        \"currency\": \"GBP\",\n",
    "        \"stops\": \"0\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    budapest_responses.append(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "bud_dataframes = []\n",
    "\n",
    "for response_text in budapest_responses:\n",
    "    bud = json.loads(response_text)[\"itineraries\"]\n",
    "    bud = bud[\"results\"]\n",
    "    flattened_data = [flatten(d) for d in bud]\n",
    "    bud = pd.DataFrame(flattened_data)\n",
    "    bud_dataframes.append(bud)\n",
    "\n",
    "bud_dep_0501 = pd.concat(bud_dataframes, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.Athens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://skyscanner44.p.rapidapi.com/search-extended\"\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": keys.api_key,\n",
    "    \"X-RapidAPI-Host\": \"skyscanner44.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "athens_responses = []\n",
    "\n",
    "\n",
    "for friday in fridays:\n",
    "    querystring = {\n",
    "        \"adults\": \"1\",\n",
    "        \"origin\": \"LOND\",\n",
    "        \"destination\": \"ATH\",\n",
    "        \"departureDate\": friday.strftime(\"%Y-%m-%d\"),\n",
    "        \"cabinClass\": \"economy\",\n",
    "        \"currency\": \"GBP\",\n",
    "        \"stops\": \"0\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    athens_responses.append(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "athens_dataframes = []\n",
    "\n",
    "for response_text in athens_responses:\n",
    "    athens = json.loads(response_text)[\"itineraries\"]\n",
    "    athens = athens[\"results\"]\n",
    "    flattened_data = [flatten(d) for d in athens]\n",
    "    athens = pd.DataFrame(flattened_data)\n",
    "    athens_dataframes.append(athens)\n",
    "\n",
    "athens_dep_0501 = pd.concat(athens_dataframes, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Firstï¼Œwe design the functions to drop unused columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns after \"pricing_options.0_price.amount\" are unneeded as they are all info about the booking agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_after_price(df):\n",
    "    \n",
    "    deeplink_index = df.columns.get_loc('pricing_options.0_price.amount')\n",
    "    df = df.iloc[:, :deeplink_index+1]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most columns contain the keywords \"segments\" are repeated, so we deleted them excluding some of them.  Ang those columns contain these keywords 'operationType', 'id', 'stopCount', 'isSmallestStops', 'timeDeltaInDays' are also unrelated to our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unused_columns(df):\n",
    "    keywords = ['segments', 'operationType', 'id', 'stopCount', 'isSmallestStops', 'timeDeltaInDays']\n",
    "    exclude_columns = ['id','legs.0_segments.0_flightNumber','legs.1_segments.0_flightNumber', 'legs.0_id', 'legs.1_id']\n",
    "    \n",
    "    columns_to_drop = [col for col in df.columns \n",
    "                       if any(keyword in part for keyword in keywords for part in col.split('_') + col.split('.')) \n",
    "                       and col not in exclude_columns]\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then we used the function to remove the complex prefix in the column names and continued to remove unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the prefix for pricing-re;ated column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix_from_columns(df):\n",
    "    prefix = 'pricing_options.0_agents.0_'\n",
    "    columns_to_rename = {col: col.replace(prefix, '') for col in df.columns if prefix in col}\n",
    "    df = df.rename(columns=columns_to_rename)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And remove the unnecessary column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df):\n",
    "    columns_to_drop = ['update_status','optimised_for_mobile', 'live_update_allowed', 'feedback_count']\n",
    "    df = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lastly, we rename the columns to make it more understandable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the 'pricing_options.0_price.amount' to 'price_amount' which is much more clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_price_column(df):\n",
    "    df = df.rename(columns={'pricing_options.0_price.amount': 'price_amount'})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As 'legs.0' stands for 'depFlight' and 'legs.1' atands for 'retFlight', we rename them to a more understandable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_legs_columns(df):\n",
    "    columns_to_rename = {col: col.replace('legs.0', 'depFlight').replace('legs.1', 'retFlight') for col in df.columns if 'legs.0' in col or 'legs.1' in col}\n",
    "    df = df.rename(columns=columns_to_rename)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the prefix which has no meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "    def replace_keywords(col):\n",
    "        col = col.replace('segments.0_', '')\n",
    "        col = col.replace('carriers.marketing.0_', '')\n",
    "        return col\n",
    "\n",
    "    renamed_columns = {col: replace_keywords(col) for col in df.columns}\n",
    "    df = df.rename(columns=renamed_columns)\n",
    "    return df\n",
    "dataframes = [rename_columns(df) for df in dataframes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'name' stands for the 'booking_agent', so we rename it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_name_column(df):\n",
    "    df = df.rename(columns={'name': 'booking_agent'})\n",
    "    return df\n",
    "dataframes = [rename_name_column(df) for df in dataframes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply those function to the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [par_0501, ber_0501, mar_0501, lis_0501,rome_0501, bud_0501, athens_0501]\n",
    "dataframes = [drop_columns_after_price(df) for df in dataframes]\n",
    "dataframes = [drop_unused_columns(df) for df in dataframes]\n",
    "dataframes = [remove_prefix_from_columns(df) for df in dataframes]\n",
    "dataframes = [drop_columns(df) for df in dataframes]\n",
    "dataframes = [rename_price_column(df) for df in dataframes]\n",
    "dataframes = [rename_legs_columns(df) for df in dataframes]\n",
    "dataframes = [rename_columns(df) for df in dataframes]\n",
    "dataframes = [rename_name_column(df) for df in dataframes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output the result to the local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_0501_cleaned = dataframes[0]\n",
    "ber_0501_cleaned = dataframes[1]\n",
    "mar_0501_cleaned = dataframes[2]\n",
    "lis_0501_cleaned = dataframes[3]\n",
    "rome_0501_cleaned = dataframes[4]\n",
    "bud_0501_cleaned = dataframes[5]\n",
    "athens_0501_cleaned = dataframes[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataframes = {\n",
    "    'paris_0501': par_0501_cleaned,\n",
    "    'berlin_0501': ber_0501_cleaned,\n",
    "    'madrid_0501': mar_0501_cleaned,\n",
    "    'lisbon_0501': lis_0501_cleaned,\n",
    "    'rome_0501': rome_0501_cleaned,\n",
    "    'budapest_0501': bud_0501_cleaned,\n",
    "    'athens_0501': athens_0501_cleaned\n",
    "}\n",
    "\n",
    "output_path = \"/Users/liuyuhan/Desktop/DS105L/depFlights_0501\"\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    file_path = os.path.join(output_path, f\"{name}.csv\")\n",
    "    df.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
